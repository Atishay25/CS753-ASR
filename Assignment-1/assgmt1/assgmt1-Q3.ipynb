{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "bKXIYTJSOnt_",
        "rtdr1VnyCQTJ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# PART I: Running a SpeechBrain ASR Recipe"
      ],
      "metadata": {
        "id": "p3S0Etz_Nokz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up the codebase."
      ],
      "metadata": {
        "id": "bKXIYTJSOnt_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "A5H2lpHX7npZ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# Clone SpeechBrain repository\n",
        "!git clone https://github.com/Darshan7575/speechbrain.git\n",
        "%cd /content/speechbrain/\n",
        "\n",
        "# Install required dependencies\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# Install SpeechBrain in editable mode\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Required imports\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import logging\n",
        "import sys\n",
        "import torch\n",
        "from pathlib import Path\n",
        "import speechbrain as sb\n",
        "from hyperpyyaml import load_hyperpyyaml\n",
        "from speechbrain.utils.data_utils import get_all_files, download_file\n",
        "from speechbrain.dataio.dataio import read_audio\n",
        "from speechbrain.utils.distributed import run_on_main, if_main_process\n",
        "\n",
        "# Required variables and loggers\n",
        "logger = logging.getLogger(__name__)\n",
        "logger = logging.getLogger(__name__)\n",
        "MINILIBRI_TRAIN_URL = \"http://www.openslr.org/resources/31/train-clean-5.tar.gz\"\n",
        "MINILIBRI_VALID_URL = \"http://www.openslr.org/resources/31/dev-clean-2.tar.gz\"\n",
        "MINILIBRI_TEST_URL = \"https://www.openslr.org/resources/12/test-clean.tar.gz\"\n",
        "SAMPLERATE = 16000\n",
        "\n",
        "device=\"cuda\"\n",
        "run_opts = {'device':device}"
      ],
      "metadata": {
        "id": "61C_gxJo5aRH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizer Training\n",
        "In this section, we will train a BPE tokenizer with **150 tokens** using `Sentencepiece`.\n",
        "\n"
      ],
      "metadata": {
        "id": "rtdr1VnyCQTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ############################################################################\n",
        "# Dataset creation helper functions\n",
        "# ############################################################################\n",
        "\n",
        "def prepare_mini_librispeech(\n",
        "    data_folder, save_json_train, save_json_valid, save_json_test\n",
        "):\n",
        "    \"\"\"\n",
        "    Prepares the json files for the Mini Librispeech dataset.\n",
        "    Downloads the dataset if its not found in the `data_folder`.\n",
        "    \"\"\"\n",
        "\n",
        "    # Check if this phase is already done (if so, skip it)\n",
        "    if skip(save_json_train, save_json_valid, save_json_test):\n",
        "        logger.info(\"Preparation completed in previous run, skipping.\")\n",
        "        return\n",
        "\n",
        "    # If the dataset doesn't exist yet, download it\n",
        "    train_folder = os.path.join(data_folder, \"LibriSpeech\", \"train-clean-5\")\n",
        "    valid_folder = os.path.join(data_folder, \"LibriSpeech\", \"dev-clean-2\")\n",
        "    test_folder = os.path.join(data_folder, \"LibriSpeech\", \"test-clean\")\n",
        "    if not check_folders(train_folder, valid_folder, test_folder):\n",
        "        download_mini_librispeech(data_folder)\n",
        "\n",
        "    # List files and create manifest from list\n",
        "    logger.info(\n",
        "        f\"Creating {save_json_train}, {save_json_valid}, and {save_json_test}\"\n",
        "    )\n",
        "    extension = [\".flac\"]\n",
        "\n",
        "    # List of flac audio files\n",
        "    wav_list_train = get_all_files(train_folder, match_and=extension)\n",
        "    wav_list_valid = get_all_files(valid_folder, match_and=extension)\n",
        "    wav_list_test = get_all_files(test_folder, match_and=extension)\n",
        "\n",
        "    # List of transcription file\n",
        "    extension = [\".trans.txt\"]\n",
        "    trans_list = get_all_files(data_folder, match_and=extension)\n",
        "    trans_dict = get_transcription(trans_list)\n",
        "\n",
        "    # Create the json files\n",
        "    create_json(wav_list_train, trans_dict, save_json_train)\n",
        "    create_json(wav_list_valid, trans_dict, save_json_valid)\n",
        "    create_json(wav_list_test, trans_dict, save_json_test)\n",
        "\n",
        "\n",
        "def get_transcription(trans_list):\n",
        "    \"\"\"\n",
        "    Returns a dictionary with the transcription of each sentence in the dataset.\n",
        "    \"\"\"\n",
        "    # Processing all the transcription files in the list\n",
        "    trans_dict = {}\n",
        "    for trans_file in trans_list:\n",
        "        # Reading the text file\n",
        "        with open(trans_file) as f:\n",
        "            for line in f:\n",
        "                uttid = line.split(\" \")[0]\n",
        "                text = line.rstrip().split(\" \")[1:]\n",
        "                text = \" \".join(text)\n",
        "                trans_dict[uttid] = text\n",
        "\n",
        "    logger.info(\"Transcription files read!\")\n",
        "    return trans_dict\n",
        "\n",
        "\n",
        "def create_json(wav_list, trans_dict, json_file):\n",
        "    \"\"\"\n",
        "    Creates the json file given a list of wav files and their transcriptions.\n",
        "    \"\"\"\n",
        "    # Processing all the wav files in the list\n",
        "    json_dict = {}\n",
        "    for wav_file in wav_list:\n",
        "\n",
        "        # Reading the signal (to retrieve duration in seconds)\n",
        "        signal = read_audio(wav_file)\n",
        "        duration = signal.shape[0] / SAMPLERATE\n",
        "\n",
        "        # Manipulate path to get relative path and uttid\n",
        "        path_parts = wav_file.split(os.path.sep)\n",
        "        uttid, _ = os.path.splitext(path_parts[-1])\n",
        "        relative_path = os.path.join(\"{data_root}\", *path_parts[-5:])\n",
        "\n",
        "        # Create entry for this utterance\n",
        "        json_dict[uttid] = {\n",
        "            \"wav\": relative_path,\n",
        "            \"length\": duration,\n",
        "            \"words\": trans_dict[uttid],\n",
        "        }\n",
        "\n",
        "    # Writing the dictionary to the json file\n",
        "    with open(json_file, mode=\"w\") as json_f:\n",
        "        json.dump(json_dict, json_f, indent=2)\n",
        "\n",
        "    logger.info(f\"{json_file} successfully created!\")\n",
        "\n",
        "\n",
        "def skip(*filenames):\n",
        "    \"\"\"\n",
        "    Detects if the data preparation has been already done.\n",
        "    If the preparation has been done, we can skip it.\n",
        "    \"\"\"\n",
        "    for filename in filenames:\n",
        "        if not os.path.isfile(filename):\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def check_folders(*folders):\n",
        "    \"\"\"Returns False if any passed folder does not exist.\"\"\"\n",
        "    for folder in folders:\n",
        "        if not os.path.exists(folder):\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def download_mini_librispeech(destination):\n",
        "    \"\"\"Download dataset and unpack it.\n",
        "    \"\"\"\n",
        "    train_archive = os.path.join(destination, \"train-clean-5.tar.gz\")\n",
        "    valid_archive = os.path.join(destination, \"dev-clean-2.tar.gz\")\n",
        "    test_archive = os.path.join(destination, \"test-clean.tar.gz\")\n",
        "    download_file(MINILIBRI_TRAIN_URL, train_archive)\n",
        "    download_file(MINILIBRI_VALID_URL, valid_archive)\n",
        "    download_file(MINILIBRI_TEST_URL, test_archive)\n",
        "    shutil.unpack_archive(train_archive, destination)\n",
        "    shutil.unpack_archive(valid_archive, destination)\n",
        "    shutil.unpack_archive(test_archive, destination)"
      ],
      "metadata": {
        "id": "ujToJHWC4T5y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_hyperparams = \"\"\"\n",
        "# ############################################################################\n",
        "# Tokenizer: subword BPE with unigram 150\n",
        "# ############################################################################\n",
        "\n",
        "output_folder: !ref results/tokenizer/\n",
        "\n",
        "# Data files\n",
        "data_folder: data\n",
        "train_annotation: !ref <data_folder>/train.json\n",
        "valid_annotation: !ref <data_folder>/valid.json\n",
        "test_annotation: !ref <data_folder>/test.json\n",
        "\n",
        "# Tokenizer training parameters\n",
        "token_type: unigram  # [\"unigram\", \"bpe\", \"char\"]\n",
        "token_output: 150  # index(blank/eos/bos/unk) = 0\n",
        "character_coverage: 1.0\n",
        "json_read: words\n",
        "\n",
        "tokenizer: !name:speechbrain.tokenizers.SentencePiece.SentencePiece\n",
        "   model_dir: !ref <output_folder>\n",
        "   vocab_size: !ref <token_output>\n",
        "   annotation_train: !ref <train_annotation>\n",
        "   annotation_read: !ref <json_read>\n",
        "   annotation_format: json\n",
        "   model_type: !ref <token_type> # [\"unigram\", \"bpe\", \"char\"]\n",
        "   character_coverage: !ref <character_coverage>\n",
        "   annotation_list_to_check: [!ref <train_annotation>, !ref <valid_annotation>]\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "rz9pyHan4V0S"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load required params from the hyperpyyaml file\n",
        "hparams = load_hyperpyyaml(tokenizer_hyperparams)\n",
        "\n",
        "# 1. Dataset creation\n",
        "\n",
        "## Create experiment directory\n",
        "sb.create_experiment_directory(\n",
        "    experiment_directory=hparams[\"output_folder\"],\n",
        "    overrides=None,\n",
        ")\n",
        "\n",
        "## Create dataset\n",
        "run_on_main(\n",
        "    prepare_mini_librispeech,\n",
        "    kwargs={\n",
        "        \"data_folder\": hparams[\"data_folder\"],\n",
        "        \"save_json_train\": hparams[\"train_annotation\"],\n",
        "        \"save_json_valid\": hparams[\"valid_annotation\"],\n",
        "        \"save_json_test\": hparams[\"test_annotation\"],\n",
        "    },\n",
        ")\n",
        "\n",
        "# 2. Tokenizer training\n",
        "hparams[\"tokenizer\"]()\n",
        "\n",
        "# 3. Saving tokenizer in .ckpt extension\n",
        "output_path = hparams[\"output_folder\"]\n",
        "token_output = hparams[\"token_output\"]\n",
        "token_type = hparams[\"token_type\"]\n",
        "bpe_model = f\"{output_path}/{token_output}_{token_type}.model\"\n",
        "tokenizer_ckpt = f\"{output_path}/tokenizer.ckpt\"\n",
        "shutil.copyfile(bpe_model, tokenizer_ckpt)"
      ],
      "metadata": {
        "id": "nA8xD6Do4Xl7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ce914442-f4a6-41c1-bf32-8d3b1c81c464"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: results/tokenizer/\n",
            "Downloading http://www.openslr.org/resources/31/train-clean-5.tar.gz to data/train-clean-5.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train-clean-5.tar.gz: 333MB [00:19, 17.1MB/s]                           \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://www.openslr.org/resources/31/dev-clean-2.tar.gz to data/dev-clean-2.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "dev-clean-2.tar.gz: 126MB [00:08, 14.6MB/s]                           \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.openslr.org/resources/12/test-clean.tar.gz to data/test-clean.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test-clean.tar.gz: 347MB [00:23, 14.7MB/s]                           \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__main__ - Creating data/train.json, data/valid.json, and data/test.json\n",
            "__main__ - Transcription files read!\n",
            "__main__ - data/train.json successfully created!\n",
            "__main__ - data/valid.json successfully created!\n",
            "__main__ - data/test.json successfully created!\n",
            "speechbrain.tokenizers.SentencePiece - Train tokenizer with type:unigram\n",
            "speechbrain.tokenizers.SentencePiece - Extract words sequences from:data/train.json\n",
            "speechbrain.tokenizers.SentencePiece - Text file created at: results/tokenizer/train.txt\n",
            "speechbrain.tokenizers.SentencePiece - ==== Loading Tokenizer ===\n",
            "speechbrain.tokenizers.SentencePiece - Tokenizer path: results/tokenizer/150_unigram.model\n",
            "speechbrain.tokenizers.SentencePiece - Tokenizer vocab_size: 150\n",
            "speechbrain.tokenizers.SentencePiece - Tokenizer type: unigram\n",
            "speechbrain.tokenizers.SentencePiece - ==== Accuracy checking for recovering text from tokenizer ===\n",
            "speechbrain.tokenizers.SentencePiece - recover words from: data/train.json\n",
            "speechbrain.tokenizers.SentencePiece - Wrong recover words: 0\n",
            "speechbrain.tokenizers.SentencePiece - accuracy recovering words: 1.0\n",
            "speechbrain.tokenizers.SentencePiece - ==== Accuracy checking for recovering text from tokenizer ===\n",
            "speechbrain.tokenizers.SentencePiece - recover words from: data/valid.json\n",
            "speechbrain.tokenizers.SentencePiece - Wrong recover words: 0\n",
            "speechbrain.tokenizers.SentencePiece - accuracy recovering words: 1.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'results/tokenizer//tokenizer.ckpt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training\n",
        "In this section, we will train a **6 layer Conformer** encoder only architecture with the `CTC objective`."
      ],
      "metadata": {
        "id": "vwqFx3QcOdd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "global_hyperparams = \"\"\"\n",
        "# Seed needs to be set at top of yaml, before objects with parameters are made\n",
        "seed: 2024\n",
        "__set_seed: !apply:torch.manual_seed [!ref <seed>]\n",
        "\n",
        "# Data files\n",
        "data_folder: data\n",
        "train_annotation: !ref ./data/train.json\n",
        "valid_annotation: !ref ./data/valid.json\n",
        "test_annotation: !ref ./data/test.json\n",
        "\n",
        "# Language model (LM) pretraining\n",
        "pretrained_lm_tokenizer_path: ./results/tokenizer\n",
        "\n",
        "# Training parameters\n",
        "number_of_epochs: 30\n",
        "batch_size: 8\n",
        "lr_adam: 0.001\n",
        "max_grad_norm: 5.0\n",
        "ckpt_interval_minutes: 15 # save checkpoint every N min\n",
        "loss_reduction: 'batchmean'\n",
        "\n",
        "# Dataloader options\n",
        "train_dataloader_opts:\n",
        "    batch_size: !ref <batch_size>\n",
        "\n",
        "valid_dataloader_opts:\n",
        "    batch_size: !ref <batch_size>\n",
        "\n",
        "test_dataloader_opts:\n",
        "    batch_size: !ref <batch_size>\n",
        "\n",
        "# Feature parameters\n",
        "sample_rate: 16000\n",
        "n_fft: 400\n",
        "n_mels: 80\n",
        "\n",
        "####################### Model parameters ###########################\n",
        "# Transformer\n",
        "d_model: 128\n",
        "nhead: 4\n",
        "num_encoder_layers: 6\n",
        "d_ffn: 512\n",
        "transformer_dropout: 0.1\n",
        "activation: !name:torch.nn.GELU\n",
        "output_neurons: 150\n",
        "label_smoothing: 0.0\n",
        "attention_type: RelPosMHAXL\n",
        "\n",
        "# Outputs\n",
        "blank_index: 0\n",
        "pad_index: 0\n",
        "bos_index: 1\n",
        "eos_index: 2\n",
        "\n",
        "# Decoding parameters\n",
        "min_decode_ratio: 0.0\n",
        "max_decode_ratio: 1.0\n",
        "test_beam_size: 1\n",
        "ctc_weight_decode: 1.0\n",
        "\n",
        "############################## models ################################\n",
        "\n",
        "compute_features: !new:speechbrain.lobes.features.Fbank\n",
        "    sample_rate: !ref <sample_rate>\n",
        "    n_fft: !ref <n_fft>\n",
        "    n_mels: !ref <n_mels>\n",
        "\n",
        "CNN: !new:speechbrain.lobes.models.convolution.ConvolutionFrontEnd\n",
        "    input_shape: (8, 10, 80)\n",
        "    num_blocks: 2\n",
        "    num_layers_per_block: 1\n",
        "    out_channels: (64, 32)\n",
        "    kernel_sizes: (3, 3)\n",
        "    strides: (2, 2)\n",
        "    residuals: (False, False)\n",
        "\n",
        "# standard parameters for the BASE model\n",
        "Transformer: !new:speechbrain.lobes.models.transformer.TransformerASR.TransformerASR\n",
        "    input_size: 640\n",
        "    tgt_vocab: !ref <output_neurons>\n",
        "    d_model: !ref <d_model>\n",
        "    nhead: !ref <nhead>\n",
        "    num_encoder_layers: !ref <num_encoder_layers>\n",
        "    num_decoder_layers: 0\n",
        "    d_ffn: !ref <d_ffn>\n",
        "    dropout: !ref <transformer_dropout>\n",
        "    activation: !ref <activation>\n",
        "    encoder_module: conformer\n",
        "    attention_type: !ref <attention_type>\n",
        "    normalize_before: True\n",
        "\n",
        "tokenizer: !new:sentencepiece.SentencePieceProcessor\n",
        "\n",
        "ctc_lin: !new:speechbrain.nnet.linear.Linear\n",
        "    input_size: !ref <d_model>\n",
        "    n_neurons: !ref <output_neurons>\n",
        "\n",
        "normalize: !new:speechbrain.processing.features.InputNormalization\n",
        "    norm_type: global\n",
        "    update_until_epoch: 4\n",
        "\n",
        "modules:\n",
        "    CNN: !ref <CNN>\n",
        "    Transformer: !ref <Transformer>\n",
        "    ctc_lin: !ref <ctc_lin>\n",
        "    normalize: !ref <normalize>\n",
        "\n",
        "model: !new:torch.nn.ModuleList\n",
        "    - [!ref <CNN>, !ref <Transformer>, !ref <ctc_lin>]\n",
        "\n",
        "# define two optimizers here for two-stage training\n",
        "Adam: !name:torch.optim.Adam\n",
        "    lr: !ref <lr_adam>\n",
        "    betas: (0.9, 0.98)\n",
        "    eps: 0.000000001\n",
        "\n",
        "log_softmax: !new:torch.nn.LogSoftmax\n",
        "    dim: -1\n",
        "\n",
        "ctc_cost: !name:speechbrain.nnet.losses.ctc_loss\n",
        "    blank_index: !ref <blank_index>\n",
        "    reduction: !ref <loss_reduction>\n",
        "\n",
        "noam_annealing: !new:speechbrain.nnet.schedulers.NoamScheduler\n",
        "    lr_initial: !ref <lr_adam>\n",
        "    n_warmup_steps: 1500\n",
        "\n",
        "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
        "    limit: !ref <number_of_epochs>\n",
        "\n",
        "error_rate_computer: !name:speechbrain.utils.metric_stats.ErrorRateStats\n",
        "\n",
        "cer_computer: !name:speechbrain.utils.metric_stats.ErrorRateStats\n",
        "   split_tokens: True\n",
        "\n",
        "# The pretrainer allows a mapping between pretrained files and instances that\n",
        "# are declared in the yaml. E.g here, we will download the file tokenizer.ckpt\n",
        "# and it will be loaded into \"tokenizer\" which is pointing to the <pretrained_lm_tokenizer_path> defined\n",
        "# before.\n",
        "pretrainer: !new:speechbrain.utils.parameter_transfer.Pretrainer\n",
        "    loadables:\n",
        "        tokenizer: !ref <tokenizer>\n",
        "    paths:\n",
        "        tokenizer: !ref <pretrained_lm_tokenizer_path>/tokenizer.ckpt\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "6WPcwXueCRm7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dataio_prepare(hparams):\n",
        "    \"\"\"This function prepares the datasets to be used in the brain class.\n",
        "    It also defines the data processing pipeline through user-defined functions.\n",
        "    \"\"\"\n",
        "    # Define audio pipeline. In this case, we simply read the path contained\n",
        "    # in the variable wav with the audio reader.\n",
        "    @sb.utils.data_pipeline.takes(\"wav\")\n",
        "    @sb.utils.data_pipeline.provides(\"sig\")\n",
        "    def audio_pipeline(wav):\n",
        "        \"\"\"Load the audio signal. This is done on the CPU in the `collate_fn`.\"\"\"\n",
        "        sig = sb.dataio.dataio.read_audio(wav)\n",
        "        return sig\n",
        "\n",
        "    tokenizer = hparams[\"tokenizer\"]\n",
        "    # Define text processing pipeline. We start from the raw text and then\n",
        "    # encode it using the tokenizer. The tokens with BOS are used for feeding\n",
        "    # decoder during training, the tokens with EOS for computing the cost function.\n",
        "    # The tokens without BOS or EOS is for computing CTC loss.\n",
        "    @sb.utils.data_pipeline.takes(\"words\")\n",
        "    @sb.utils.data_pipeline.provides(\n",
        "        \"wrd\", \"tokens_list\", \"tokens_bos\", \"tokens_eos\", \"tokens\"\n",
        "    )\n",
        "    def text_pipeline(wrd):\n",
        "        \"\"\"Processes the transcriptions to generate proper labels\"\"\"\n",
        "        yield wrd\n",
        "        tokens_list = tokenizer.encode_as_ids(wrd)\n",
        "        yield tokens_list\n",
        "        tokens_bos = torch.LongTensor([hparams[\"bos_index\"]] + (tokens_list))\n",
        "        yield tokens_bos\n",
        "        tokens_eos = torch.LongTensor(tokens_list + [hparams[\"eos_index\"]])\n",
        "        yield tokens_eos\n",
        "        tokens = torch.LongTensor(tokens_list)\n",
        "        yield tokens\n",
        "\n",
        "    # Define datasets from json data manifest file\n",
        "    # Define datasets sorted by ascending lengths for efficiency\n",
        "    datasets = {}\n",
        "    data_folder = hparams[\"data_folder\"]\n",
        "    for dataset in [\"train\", \"valid\", \"test\"]:\n",
        "        datasets[dataset] = sb.dataio.dataset.DynamicItemDataset.from_json(\n",
        "            json_path=hparams[f\"{dataset}_annotation\"],\n",
        "            replacements={\"data_root\": data_folder},\n",
        "            dynamic_items=[audio_pipeline, text_pipeline],\n",
        "            output_keys=[\n",
        "                \"id\",\n",
        "                \"sig\",\n",
        "                \"wrd\",\n",
        "                \"tokens_bos\",\n",
        "                \"tokens_eos\",\n",
        "                \"tokens\",\n",
        "            ],\n",
        "        )\n",
        "        hparams[f\"{dataset}_dataloader_opts\"][\"shuffle\"] = False\n",
        "\n",
        "    datasets[\"train\"] = datasets[\"train\"].filtered_sorted(sort_key=\"length\")\n",
        "    hparams[\"train_dataloader_opts\"][\"shuffle\"] = False\n",
        "\n",
        "    return (\n",
        "        datasets[\"train\"],\n",
        "        datasets[\"valid\"],\n",
        "        datasets[\"test\"],\n",
        "        tokenizer\n",
        "    )"
      ],
      "metadata": {
        "id": "euJMqDLSWv7Y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training procedure\n",
        "class BaseASR(sb.Brain):\n",
        "    def __init__(\n",
        "        self,\n",
        "        modules=None,\n",
        "        opt_class=None,\n",
        "        hparams=None,\n",
        "        run_opts=None,\n",
        "        checkpointer=None,\n",
        "        profiler=None,\n",
        "        tokenizer=None,\n",
        "    ):\n",
        "        super(BaseASR, self).__init__(\n",
        "            modules=modules,\n",
        "            opt_class=opt_class,\n",
        "            hparams=hparams,\n",
        "            run_opts=run_opts,\n",
        "            checkpointer=checkpointer,\n",
        "            profiler=profiler\n",
        "        )\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def compute_forward(self, batch, stage):\n",
        "        \"\"\"Performs a forward pass through the encoder\"\"\"\n",
        "        batch = batch.to(self.device)\n",
        "        wavs, wav_lens = batch.sig\n",
        "        tokens_bos, _ = batch.tokens_bos\n",
        "\n",
        "        # compute features\n",
        "        feats = self.hparams.compute_features(wavs) #### FILL THIS WITH YOUR CODE FROM PART I ####\n",
        "        current_epoch = self.hparams.epoch_counter.current\n",
        "        feats = self.modules.normalize(feats, wav_lens, epoch=current_epoch)\n",
        "\n",
        "        # forward modules\n",
        "        src = self.modules.CNN(feats)\n",
        "\n",
        "        enc_out, _ = self.modules.Transformer(\n",
        "            src, tokens_bos, wav_lens, pad_idx=self.hparams.pad_index,\n",
        "        )\n",
        "\n",
        "        # output layer for ctc log-probabilities\n",
        "        logits = self.modules.ctc_lin(enc_out)\n",
        "        p_ctc = self.hparams.log_softmax(logits) #### FILL THIS WITH YOUR CODE FROM PART I ####\n",
        "\n",
        "        # Compute outputs\n",
        "        hyps = None\n",
        "        if stage == sb.Stage.TRAIN:\n",
        "            hyps = None\n",
        "        else:\n",
        "            hyps = sb.decoders.ctc_greedy_decode(\n",
        "                p_ctc, wav_lens, blank_id=self.hparams.blank_index\n",
        "            )\n",
        "\n",
        "        return p_ctc, wav_lens, hyps\n",
        "\n",
        "    def get_ctc_probs(self, batch):\n",
        "        batch = batch.to(self.device)\n",
        "        wavs, wav_lens = batch.sig\n",
        "        tokens_bos, _ = batch.tokens_bos\n",
        "\n",
        "        # compute features\n",
        "        feats = self.hparams.compute_features(wavs)\n",
        "        current_epoch = self.hparams.epoch_counter.current\n",
        "        feats = self.modules.normalize(feats, wav_lens, epoch=current_epoch)\n",
        "\n",
        "        # forward modules\n",
        "        src = self.modules.CNN(feats)\n",
        "\n",
        "        enc_out, _ = self.modules.Transformer(\n",
        "            src, tokens_bos, wav_lens, pad_idx=self.hparams.pad_index,\n",
        "        )\n",
        "\n",
        "        logits = self.modules.ctc_lin(enc_out)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def compute_objectives(self, predictions, batch, stage):\n",
        "        \"\"\"Computes the CTC loss given predictions and targets.\"\"\"\n",
        "\n",
        "        (p_ctc, wav_lens, hyps,) = predictions\n",
        "\n",
        "        ids = batch.id\n",
        "        tokens_eos, tokens_eos_lens = batch.tokens_eos\n",
        "        tokens, tokens_lens = batch.tokens\n",
        "\n",
        "        # Calculate CTC loss\n",
        "        loss = self.hparams.ctc_cost(p_ctc, tokens, wav_lens, tokens_lens) #### FILL THIS WITH YOUR CODE FROM PART I ####\n",
        "\n",
        "        if stage != sb.Stage.TRAIN:\n",
        "            # Decode token terms to words\n",
        "            predicted_words = [\n",
        "                self.tokenizer.decode_ids(utt_seq).split(\" \") for utt_seq in hyps\n",
        "            ]\n",
        "            target_words = [wrd.split(\" \") for wrd in batch.wrd]\n",
        "            self.wer_metric.append(ids, predicted_words, target_words)\n",
        "            self.cer_metric.append(ids, predicted_words, target_words)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def on_evaluate_start(self, max_key=None, min_key=None):\n",
        "        \"\"\"Performs checkpoint averge if needed\"\"\"\n",
        "        super().on_evaluate_start()\n",
        "\n",
        "        ckpts = self.checkpointer.find_checkpoints(\n",
        "            max_key=max_key, min_key=min_key\n",
        "        )\n",
        "        ckpt = sb.utils.checkpoints.average_checkpoints(\n",
        "            ckpts, recoverable_name=\"model\", device=self.device\n",
        "        )\n",
        "\n",
        "        self.hparams.model.load_state_dict(ckpt, strict=True)\n",
        "        self.hparams.model.eval()\n",
        "        print(\"Loaded the average\")\n",
        "\n",
        "    def evaluate_batch(self, batch, stage):\n",
        "        \"\"\"Computations needed for validation/test batches\"\"\"\n",
        "        with torch.no_grad():\n",
        "            predictions = self.compute_forward(batch, stage=stage)\n",
        "            loss = self.compute_objectives(predictions, batch, stage=stage)\n",
        "        return loss.detach()\n",
        "\n",
        "    def on_stage_start(self, stage, epoch):\n",
        "        \"\"\"Gets called at the beginning of each epoch\"\"\"\n",
        "        if stage != sb.Stage.TRAIN:\n",
        "            self.cer_metric = self.hparams.cer_computer()\n",
        "            self.wer_metric = self.hparams.error_rate_computer()\n",
        "\n",
        "    def on_stage_end(self, stage, stage_loss, epoch):\n",
        "        \"\"\"Gets called at the end of a epoch.\"\"\"\n",
        "        # Compute/store important stats\n",
        "        stage_stats = {\"loss\": stage_loss}\n",
        "        if stage == sb.Stage.TRAIN:\n",
        "            self.train_stats = stage_stats\n",
        "        else:\n",
        "            stage_stats[\"CER\"] = self.cer_metric.summarize(\"error_rate\")\n",
        "            stage_stats[\"WER\"] = self.wer_metric.summarize(\"error_rate\")\n",
        "\n",
        "        # log stats and save checkpoint at end-of-epoch\n",
        "        if stage == sb.Stage.VALID and sb.utils.distributed.if_main_process():\n",
        "\n",
        "            lr = self.hparams.noam_annealing.current_lr\n",
        "            steps = self.optimizer_step\n",
        "            optimizer = self.optimizer.__class__.__name__\n",
        "\n",
        "            epoch_stats = {\n",
        "                \"epoch\": epoch,\n",
        "                \"lr\": lr,\n",
        "                \"steps\": steps,\n",
        "                \"optimizer\": optimizer,\n",
        "            }\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                stats_meta=epoch_stats,\n",
        "                train_stats=self.train_stats,\n",
        "                valid_stats=stage_stats,\n",
        "            )\n",
        "            # Save only last 10 checkpoints\n",
        "            self.checkpointer.save_and_keep_only(\n",
        "                meta={\"loss\": stage_loss, \"epoch\": epoch},\n",
        "                max_keys=[\"epoch\"],\n",
        "                num_to_keep=10,\n",
        "            )\n",
        "\n",
        "        elif stage == sb.Stage.TEST:\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                stats_meta={\"Epoch loaded\": self.hparams.epoch_counter.current},\n",
        "                test_stats=stage_stats,\n",
        "            )\n",
        "            # Write the WER metric for test dataset\n",
        "            if if_main_process():\n",
        "                with open(self.hparams.test_wer_file, \"w\") as w:\n",
        "                    self.wer_metric.write_stats(w)\n",
        "\n",
        "    def fit_batch(self, batch):\n",
        "        \"\"\"Performs a forward + backward pass on 1 batch\n",
        "        \"\"\"\n",
        "\n",
        "        should_step = self.step % self.grad_accumulation_factor == 0\n",
        "\n",
        "        outputs = self.compute_forward(batch, sb.Stage.TRAIN)\n",
        "        loss = self.compute_objectives(outputs, batch, sb.Stage.TRAIN)\n",
        "        loss.backward()\n",
        "        if self.check_gradients(loss):\n",
        "            self.optimizer.step()\n",
        "        self.zero_grad()\n",
        "        self.optimizer_step += 1\n",
        "        self.hparams.noam_annealing(self.optimizer)\n",
        "\n",
        "        self.on_fit_batch_end(batch, outputs, loss, should_step)\n",
        "        return loss.detach().cpu()"
      ],
      "metadata": {
        "id": "wUEBBUOQZ4V-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task_hyperparameters = \"\"\"\n",
        "# Setup the directory to host experiment results\n",
        "output_folder: !ref results/transformer/Task_1\n",
        "wer_file: !ref <output_folder>/wer.txt\n",
        "save_folder: !ref <output_folder>/save\n",
        "train_log: !ref <output_folder>/train_log.txt\n",
        "\n",
        "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
        "    save_file: !ref <train_log>\n",
        "\n",
        "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
        "    checkpoints_dir: !ref <save_folder>\n",
        "    recoverables:\n",
        "        model: !ref <model>\n",
        "        noam_scheduler: !ref <noam_annealing>\n",
        "        normalizer: !ref <normalize>\n",
        "        counter: !ref <epoch_counter>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "DDQEQ8M2MNAi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparams = global_hyperparams + task_hyperparameters\n",
        "hparams = load_hyperpyyaml(hyperparams)\n",
        "\n",
        "# Create experiment directory\n",
        "sb.create_experiment_directory(\n",
        "    experiment_directory=hparams[\"output_folder\"],\n",
        "    overrides=None,\n",
        ")\n",
        "\n",
        "# Here we create the datasets objects as well as tokenization and encoding\n",
        "(\n",
        "    train_data,\n",
        "    valid_data,\n",
        "    test_data,\n",
        "    tokenizer\n",
        ") = dataio_prepare(hparams)\n",
        "\n",
        "# We download the pretrained LM from HuggingFace (or elsewhere depending on\n",
        "# the path given in the YAML file). The tokenizer is loaded at the same time.\n",
        "run_on_main(hparams[\"pretrainer\"].collect_files)\n",
        "hparams[\"pretrainer\"].load_collected(device=run_opts[\"device\"])\n",
        "\n",
        "# Trainer initialization\n",
        "asr_brain = BaseASR(\n",
        "    modules=hparams[\"modules\"],\n",
        "    opt_class=hparams[\"Adam\"],\n",
        "    hparams=hparams,\n",
        "    checkpointer=hparams[\"checkpointer\"],\n",
        "    run_opts=run_opts,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# adding objects to trainer:\n",
        "train_dataloader_opts = hparams[\"train_dataloader_opts\"]\n",
        "valid_dataloader_opts = hparams[\"valid_dataloader_opts\"]\n",
        "\n",
        "# Training\n",
        "\n",
        "asr_brain.fit(\n",
        "    asr_brain.hparams.epoch_counter,\n",
        "    train_data,\n",
        "    valid_data,\n",
        "    train_loader_kwargs=train_dataloader_opts,\n",
        "    valid_loader_kwargs=valid_dataloader_opts\n",
        ")\n",
        "\n",
        "# Testing\n",
        "asr_brain.hparams.test_wer_file = asr_brain.hparams.wer_file\n",
        "asr_brain.evaluate(\n",
        "    train_data,\n",
        "    max_key=\"epoch\",\n",
        "    test_loader_kwargs=hparams[\"train_dataloader_opts\"],\n",
        ")"
      ],
      "metadata": {
        "id": "tGonNC7u8hlJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59377668-c746-4974-e7cf-7cf899244b26"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: results/transformer/Task_1\n",
            "speechbrain.pretrained.fetching - Destination tokenizer.ckpt: local file in /content/speechbrain/results/tokenizer/tokenizer.ckpt.\n",
            "speechbrain.utils.parameter_transfer - Set local path in self.paths[tokenizer] = model_checkpoints/tokenizer.ckpt\n",
            "speechbrain.utils.parameter_transfer - Loading pretrained files for: tokenizer\n",
            "speechbrain.utils.parameter_transfer - Redirecting (loading from local path): model_checkpoints/tokenizer.ckpt -> model_checkpoints/tokenizer.ckpt\n",
            "speechbrain.core - Info: max_grad_norm arg from hparam file is used\n",
            "speechbrain.core - Info: ckpt_interval_minutes arg from hparam file is used\n",
            "speechbrain.core - 2.6M trainable parameters in BaseASR\n",
            "speechbrain.utils.checkpoints - Would load a checkpoint here, but none found yet.\n",
            "speechbrain.utils.epoch_loop - Going into epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:40<00:00,  4.64it/s, train_loss=474]\n",
            "100%|██████████| 137/137 [00:09<00:00, 14.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 1, lr: 1.26e-04, steps: 190, optimizer: Adam - train loss: 4.74e+02 - valid loss: 2.35e+02, valid CER: 1.00e+02, valid WER: 1.00e+02\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-46-32+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 190/190 [00:29<00:00,  6.48it/s, train_loss=431]\n",
            "100%|██████████| 137/137 [00:08<00:00, 15.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 2, lr: 2.53e-04, steps: 380, optimizer: Adam - train loss: 4.31e+02 - valid loss: 2.34e+02, valid CER: 1.00e+02, valid WER: 1.00e+02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-47-10+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.84it/s, train_loss=430]\n",
            "100%|██████████| 137/137 [00:09<00:00, 13.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 3, lr: 3.79e-04, steps: 570, optimizer: Adam - train loss: 4.30e+02 - valid loss: 2.32e+02, valid CER: 1.00e+02, valid WER: 1.00e+02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-47-48+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.82it/s, train_loss=409]\n",
            "100%|██████████| 137/137 [00:10<00:00, 12.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 4, lr: 5.06e-04, steps: 760, optimizer: Adam - train loss: 4.09e+02 - valid loss: 2.08e+02, valid CER: 83.35, valid WER: 95.93\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-48-26+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 190/190 [00:27<00:00,  6.90it/s, train_loss=350]\n",
            "100%|██████████| 137/137 [00:12<00:00, 11.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 5, lr: 6.33e-04, steps: 950, optimizer: Adam - train loss: 3.50e+02 - valid loss: 1.77e+02, valid CER: 71.15, valid WER: 93.00\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-49-06+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 190/190 [00:28<00:00,  6.78it/s, train_loss=306]\n",
            "100%|██████████| 137/137 [00:12<00:00, 10.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 6, lr: 7.59e-04, steps: 1140, optimizer: Adam - train loss: 3.06e+02 - valid loss: 1.60e+02, valid CER: 63.53, valid WER: 91.43\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-49-47+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.epoch_loop - Going into epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.84it/s, train_loss=272]\n",
            "100%|██████████| 137/137 [00:13<00:00, 10.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 7, lr: 8.86e-04, steps: 1330, optimizer: Adam - train loss: 2.72e+02 - valid loss: 1.45e+02, valid CER: 56.16, valid WER: 88.19\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-50-29+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.epoch_loop - Going into epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.82it/s, train_loss=245]\n",
            "100%|██████████| 137/137 [00:14<00:00,  9.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 8, lr: 9.94e-04, steps: 1520, optimizer: Adam - train loss: 2.45e+02 - valid loss: 1.34e+02, valid CER: 51.31, valid WER: 85.78\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-51-11+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.epoch_loop - Going into epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:30<00:00,  6.33it/s, train_loss=220]\n",
            "100%|██████████| 137/137 [00:14<00:00,  9.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 9, lr: 9.37e-04, steps: 1710, optimizer: Adam - train loss: 2.20e+02 - valid loss: 1.25e+02, valid CER: 47.70, valid WER: 84.42\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-51-56+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.epoch_loop - Going into epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:28<00:00,  6.69it/s, train_loss=199]\n",
            "100%|██████████| 137/137 [00:14<00:00,  9.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 10, lr: 8.89e-04, steps: 1900, optimizer: Adam - train loss: 1.99e+02 - valid loss: 1.19e+02, valid CER: 44.26, valid WER: 82.60\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-52-39+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.epoch_loop - Going into epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.83it/s, train_loss=181]\n",
            "100%|██████████| 137/137 [00:15<00:00,  8.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 11, lr: 8.47e-04, steps: 2090, optimizer: Adam - train loss: 1.81e+02 - valid loss: 1.14e+02, valid CER: 42.77, valid WER: 80.72\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-53-23+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-46-32+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.90it/s, train_loss=166]\n",
            "100%|██████████| 137/137 [00:14<00:00,  9.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 12, lr: 8.11e-04, steps: 2280, optimizer: Adam - train loss: 1.66e+02 - valid loss: 1.11e+02, valid CER: 40.95, valid WER: 79.96\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-54-05+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-47-10+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:28<00:00,  6.77it/s, train_loss=153]\n",
            "100%|██████████| 137/137 [00:14<00:00,  9.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 13, lr: 7.79e-04, steps: 2470, optimizer: Adam - train loss: 1.53e+02 - valid loss: 1.09e+02, valid CER: 39.65, valid WER: 78.22\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-54-49+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-47-48+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.90it/s, train_loss=142]\n",
            "100%|██████████| 137/137 [00:15<00:00,  9.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 14, lr: 7.51e-04, steps: 2660, optimizer: Adam - train loss: 1.42e+02 - valid loss: 1.09e+02, valid CER: 39.72, valid WER: 77.94\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-55-32+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-48-26+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.80it/s, train_loss=131]\n",
            "100%|██████████| 137/137 [00:15<00:00,  9.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 15, lr: 7.26e-04, steps: 2850, optimizer: Adam - train loss: 1.31e+02 - valid loss: 1.08e+02, valid CER: 38.17, valid WER: 76.34\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-56-15+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-49-06+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.86it/s, train_loss=121]\n",
            "100%|██████████| 137/137 [00:15<00:00,  8.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 16, lr: 7.03e-04, steps: 3040, optimizer: Adam - train loss: 1.21e+02 - valid loss: 1.08e+02, valid CER: 37.87, valid WER: 76.34\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-56-59+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-49-47+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.94it/s, train_loss=113]\n",
            "100%|██████████| 137/137 [00:15<00:00,  8.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 17, lr: 6.82e-04, steps: 3230, optimizer: Adam - train loss: 1.13e+02 - valid loss: 1.07e+02, valid CER: 37.00, valid WER: 75.40\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-57-42+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-50-29+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:30<00:00,  6.29it/s, train_loss=106]\n",
            "100%|██████████| 137/137 [00:15<00:00,  8.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 18, lr: 6.62e-04, steps: 3420, optimizer: Adam - train loss: 1.06e+02 - valid loss: 1.10e+02, valid CER: 37.33, valid WER: 75.99\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-58-28+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-51-11+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:41<00:00,  4.63it/s, train_loss=99.2]\n",
            "100%|██████████| 137/137 [00:22<00:00,  6.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 19, lr: 6.45e-04, steps: 3610, optimizer: Adam - train loss: 99.20 - valid loss: 1.08e+02, valid CER: 36.14, valid WER: 75.11\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-59-32+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-51-56+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:28<00:00,  6.72it/s, train_loss=92.6]\n",
            "100%|██████████| 137/137 [00:15<00:00,  8.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 20, lr: 6.28e-04, steps: 3800, optimizer: Adam - train loss: 92.56 - valid loss: 1.10e+02, valid CER: 36.66, valid WER: 74.75\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+09-00-16+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-52-39+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.79it/s, train_loss=86.8]\n",
            "100%|██████████| 137/137 [00:16<00:00,  8.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 21, lr: 6.13e-04, steps: 3990, optimizer: Adam - train loss: 86.80 - valid loss: 1.10e+02, valid CER: 36.09, valid WER: 73.42\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+09-01-02+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-53-23+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:28<00:00,  6.59it/s, train_loss=81.4]\n",
            "100%|██████████| 137/137 [00:16<00:00,  8.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 22, lr: 5.99e-04, steps: 4180, optimizer: Adam - train loss: 81.42 - valid loss: 1.12e+02, valid CER: 35.74, valid WER: 73.39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+09-01-47+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-54-05+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.79it/s, train_loss=76.7]\n",
            "100%|██████████| 137/137 [00:15<00:00,  8.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 23, lr: 5.86e-04, steps: 4370, optimizer: Adam - train loss: 76.71 - valid loss: 1.15e+02, valid CER: 36.18, valid WER: 73.61\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+09-02-31+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-54-49+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:28<00:00,  6.67it/s, train_loss=72.2]\n",
            "100%|██████████| 137/137 [00:15<00:00,  8.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 24, lr: 5.74e-04, steps: 4560, optimizer: Adam - train loss: 72.15 - valid loss: 1.16e+02, valid CER: 35.93, valid WER: 72.88\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+09-03-16+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-55-32+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.84it/s, train_loss=68]\n",
            "100%|██████████| 137/137 [00:16<00:00,  8.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 25, lr: 5.62e-04, steps: 4750, optimizer: Adam - train loss: 67.98 - valid loss: 1.15e+02, valid CER: 35.06, valid WER: 73.03\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+09-04-01+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-56-15+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.89it/s, train_loss=64.3]\n",
            "100%|██████████| 137/137 [00:15<00:00,  8.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 26, lr: 5.51e-04, steps: 4940, optimizer: Adam - train loss: 64.26 - valid loss: 1.15e+02, valid CER: 34.99, valid WER: 72.94\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+09-04-44+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-56-59+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:28<00:00,  6.71it/s, train_loss=60.2]\n",
            "100%|██████████| 137/137 [00:15<00:00,  8.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 27, lr: 5.41e-04, steps: 5130, optimizer: Adam - train loss: 60.24 - valid loss: 1.19e+02, valid CER: 35.05, valid WER: 72.85\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+09-05-29+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-57-42+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:28<00:00,  6.77it/s, train_loss=57.2]\n",
            "100%|██████████| 137/137 [00:16<00:00,  8.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 28, lr: 5.31e-04, steps: 5320, optimizer: Adam - train loss: 57.22 - valid loss: 1.21e+02, valid CER: 34.95, valid WER: 72.79\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+09-06-14+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-58-28+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:28<00:00,  6.78it/s, train_loss=53.9]\n",
            "100%|██████████| 137/137 [00:16<00:00,  8.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 29, lr: 5.22e-04, steps: 5510, optimizer: Adam - train loss: 53.89 - valid loss: 1.22e+02, valid CER: 34.74, valid WER: 73.27\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+09-06-59+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+08-59-32+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.85it/s, train_loss=51.4]\n",
            "100%|██████████| 137/137 [00:15<00:00,  8.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 30, lr: 5.13e-04, steps: 5700, optimizer: Adam - train loss: 51.40 - valid loss: 1.24e+02, valid CER: 34.60, valid WER: 73.51\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+09-07-43+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-18+09-00-16+00\n",
            "speechbrain.utils.checkpoints - Loading a checkpoint from results/transformer/Task_1/save/CKPT+2024-02-18+09-07-43+00\n",
            "Loaded the average\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:43<00:00,  4.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - Epoch loaded: 30 - test loss: 28.70, test CER: 6.07, test WER: 20.81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28.695060063271146"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART III: Visualizing CTC alignments"
      ],
      "metadata": {
        "id": "JbkMK32DJpHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "(\n",
        "    train_data,\n",
        "    valid_data,\n",
        "    test_data,\n",
        "    _\n",
        ") = dataio_prepare(hparams)\n",
        "\n",
        "#Creating a test dataloader to get model results on test audio\n",
        "hparams['train_dataloader_opts']['batch_size'] = 8\n",
        "test_loader = asr_brain.make_dataloader(test_data, sb.Stage.TEST, **hparams[\"train_dataloader_opts\"])\n",
        "results = None\n",
        "\n",
        "#Creating a batch for the test dataloader and getting model results\n",
        "for batch in test_loader:\n",
        "    ground_truth_tokens = batch.tokens[0]\n",
        "    target_lens = (ground_truth_tokens != 0).sum(-1)\n",
        "    _, input_lens = batch.sig\n",
        "    results = asr_brain.compute_forward(batch, sb.Stage.TEST)[0]\n",
        "    input_lens = torch.round(input_lens * results.shape[1]).to(torch.int)\n",
        "    break\n",
        "print(results.shape)"
      ],
      "metadata": {
        "id": "zIfWCEVTJvYN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e9a68d1-f2ae-459b-9292-fb58b7e7d32d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 538, 150])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def logadd(x0, x1, x2):\n",
        "\t# produces nan gradients in backward if -inf log-space zero element is used https://github.com/pytorch/pytorch/issues/31829\n",
        "\treturn torch.logsumexp(torch.stack([x0, x1, x2]), dim = 0)"
      ],
      "metadata": {
        "id": "9b4G2mMaBzsV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ctc_alignment(log_probs : torch.Tensor, targets : torch.Tensor, input_lengths : torch.Tensor, target_lengths : torch.Tensor, blank : int = 0):\n",
        "    '''\n",
        "    this function computes the ctc-alignment matrix, then performs a backward-algorithm\n",
        "    pass on it to find the best state sequence (states being the transformer states here).\n",
        "    the ctc-algorithm equations can be found on the 3rd slide of the following link -\n",
        "    https://www.cse.iitb.ac.in/~pjyothi/cs753/slides/lecture15.pdf\n",
        "    keep in mind that the equations are 1-indexed while our implementation is 0-indexed\n",
        "    '''\n",
        "    max_input_len, batch_size, num_tokens = log_probs.shape\n",
        "    _, max_target_len = targets.shape\n",
        "    batch_arange = torch.arange(batch_size, device = input_lengths.device)\n",
        "    ##############################\n",
        "    # TODO(1) - add \"_\" (blank) token alternatively to target sequence (starting and ending with \"_\")\n",
        "    # example - \"a man saw a cat\" should become \"_a_ _m_a_n_ _s_a_w_ _a_ _c_a_t_\"\n",
        "    # (assuming that each character is one token; a token might be >1 characters long)\n",
        "    # if the original sequence had L tokens, `padded_targets` should now have 2*L+1 tokens\n",
        "    padded_targets = torch.zeros(batch_size, 2 * max_target_len + 1, dtype=torch.int64) ### Complete this\n",
        "    padded_targets[:, 1::2] = targets\n",
        "    padded_targets[:, ::2] = blank\n",
        "    ##############################\n",
        "    assert padded_targets.shape == (batch_size, 2 * max_target_len + 1)\n",
        "\n",
        "    # Compute positions where target[j] != target[j-2]\n",
        "    diff_labels = torch.cat([\n",
        "        torch.as_tensor([[False, False]], device = targets.device).expand(len(batch_arange), -1),\n",
        "        padded_targets[:, 2:] != padded_targets[:, :-2]\n",
        "    ], dim = 1)\n",
        "    # Gather log-probs per input sequence index for tokens in target sequence\n",
        "    log_probs_for_targets = log_probs.gather(-1, padded_targets.unsqueeze(0).repeat(max_input_len, 1, 1))\n",
        "    assert log_probs_for_targets.shape == (max_input_len, batch_size, max_target_len * 2 + 1)\n",
        "\n",
        "    # To avoid nan grad in torch.logsumexp\n",
        "    min_element = torch.finfo(log_probs.dtype).min\n",
        "\n",
        "    # Padding is required at the start of log_alpha for vectorization\n",
        "    # Allows using torch.where for the i=j-2 step of ctc alignment computation\n",
        "    zero_padding = 2\n",
        "\n",
        "    # `log_alpha` is the ctc-probability matrix\n",
        "    # We want to deal in the logarithm-space since the probabilities can end up\n",
        "    # becoming very small and naive multiplication of small numbers can be imprecise.\n",
        "    # Note that usual-multiplication -> log-addition.\n",
        "    # Also note the utility of `logadd` function\n",
        "    log_alpha = torch.full(\n",
        "        size = (max_input_len, batch_size, zero_padding + padded_targets.shape[-1]),\n",
        "        fill_value = min_element, device = log_probs.device, dtype = log_probs.dtype\n",
        "    )\n",
        "\n",
        "    ##############################\n",
        "    # TODO(2) - initialization of ctc-probability matrix\n",
        "    # alpha[0] is non-zero only for first blank (\"_\") and first non-blank token\n",
        "    log_alpha[0, :, zero_padding + 0] = log_probs_for_targets[0, :, 0] ### Complete this\n",
        "    log_alpha[0, :, zero_padding + 1] = log_probs_for_targets[0, :, 1] ### Complete this\n",
        "    ##############################\n",
        "\n",
        "    # iterate over input sequence\n",
        "    for t in range(1, max_input_len):\n",
        "        ##############################\n",
        "        # TODO(3) - compute updates using indices j, j-1, j-2; refer to slides\n",
        "        # note that updates for j-2 are conditional upon y[j-2] != y[j], use torch.where\n",
        "        # with a suitable boolean tensor defined above\n",
        "        update_j = log_alpha[t-1, :, zero_padding:]### Complete this\n",
        "        update_j_minus_1 = log_alpha[t-1, :, (zero_padding-1):-1]### Complete this\n",
        "        update_j_minus_2 = torch.where(diff_labels, log_alpha[t-1, :, (zero_padding - 2):-2], torch.tensor(min_element, device = log_probs.device))### Complete this\n",
        "\n",
        "        ##############################\n",
        "\n",
        "        # multiplying with probability is equiv. to adding in the log space\n",
        "        log_alpha[t, :, zero_padding:] = logadd(\n",
        "            update_j,\n",
        "            update_j_minus_1,\n",
        "            update_j_minus_2\n",
        "        ) + log_probs_for_targets[t]\n",
        "\n",
        "    ##############################\n",
        "    # TODO(4) - compute ctc loss terms\n",
        "    # refer to slides, the CTC(x, y) equation - loss is from time step T, tokens 2l, 2l+1\n",
        "    # T might be different for different sequences, use `input_lengths` for that\n",
        "    # l might be different for different sequences, use `target_lengths` for that\n",
        "    indices_2_0 = zero_padding +  2 * (target_lengths) - 1\n",
        "    indices_2_1 = zero_padding + 2 * target_lengths\n",
        "    ctc_0 = log_alpha[input_lengths.long() - 1, batch_arange, indices_2_0]\n",
        "    ctc_1 = log_alpha[input_lengths.long() - 1, batch_arange, indices_2_1]\n",
        "    ctc_loss_term = torch.stack([ctc_0, ctc_1], dim=-1)### Complete this computation. You will likely need to define\n",
        "    ### new helper variables to help with this computation.\n",
        "    ##############################\n",
        "    assert ctc_loss_term.shape == (batch_size, 2)\n",
        "\n",
        "    # `path` stores the best hidden state sequence\n",
        "    path = torch.zeros(max_input_len, batch_size, device = log_alpha.device, dtype = torch.int64)\n",
        "\n",
        "    # at timestep T, best index is 2l or 2l+1\n",
        "    path[input_lengths - 1, batch_arange] = zero_padding + 2 * target_lengths - 1 + ctc_loss_term.argmax(dim = -1)\n",
        "\n",
        "    for t, indices in reversed(list(enumerate(path))[1:]):\n",
        "        ##############################\n",
        "        # TODO(5) - compute possible previous states given the current best states in `indices`\n",
        "        # previous states could come from transition i->j where i can be j, j-1 or j-2 (if y[j] != y[j-2])\n",
        "        # if y[j] == y[j-2], use 0 as possible previous state; since 0 is a padding state,\n",
        "        # log_alpha will be very low and argmax below would take care of it.\n",
        "        # such tricks to handle corner-cases help vectorize code in a better fashion.\n",
        "        possible_previous_states = torch.stack([torch.where(diff_labels[batch_arange, indices-2], indices-2, torch.tensor(0, device=log_alpha.device)), indices-1, indices], dim=-1)### Complete this\n",
        "        possible_previous_states = possible_previous_states.clamp(min=0)\n",
        "        ##############################\n",
        "        assert possible_previous_states.shape == (batch_size, 3)\n",
        "\n",
        "        # get best possible previous state\n",
        "        argmax_among_prev_states = log_alpha[t - 1, batch_arange].gather(-1, possible_previous_states).argmax(dim = -1)\n",
        "        path[t - 1] += (indices - 2 + argmax_among_prev_states).clamp(min = 0)\n",
        "\n",
        "    # color correct (input_index, target_index) cell\n",
        "    # `highlighted_best_path` is a binary (0-1) matrix\n",
        "    highlighted_best_path = torch.zeros_like(log_alpha).scatter_(\n",
        "        dim = -1,\n",
        "        index = path.unsqueeze(-1),\n",
        "        value = 1.0\n",
        "    )[..., (zero_padding + 1):]\n",
        "\n",
        "    # compute unpadded best path\n",
        "    # `highlighted_best_path` can have blank's (\"_\"), we want a mapping to the non-blank tokens only\n",
        "    # (assumed convention) when removing padding, we assign a blank token's positions to the previous token;\n",
        "    # note that the foremost blank token has already been removed above\n",
        "    unpadded_best_path = highlighted_best_path.reshape(max_input_len, batch_size, max_target_len, 2).sum(-1)\n",
        "    assert unpadded_best_path.shape == (max_input_len, batch_size, max_target_len)\n",
        "\n",
        "    return unpadded_best_path"
      ],
      "metadata": {
        "id": "gBADwCu24x3L"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Computing CTC alignments using the model results\n",
        "results_in = results.cpu().transpose(0,1)\n",
        "alignment = ctc_alignment(results_in, ground_truth_tokens, input_lens, target_lens, blank = 0)\n",
        "alignment = alignment[:,0, :target_lens[0]]"
      ],
      "metadata": {
        "id": "KBHYK7so-G2j"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizer is an object of the SentencePieceProcessor class,\n",
        "# Create an array of all the tokens of tokenizer, arranged according to their token IDs\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Get the total number of tokens in the model\n",
        "def array_of_all_tokens(tokenizer):\n",
        "    num_tokens = tokenizer.get_piece_size()\n",
        "\n",
        "    all_tokens_and_ids = [(tokenizer.id_to_piece(token_id), token_id) for token_id in range(num_tokens)]\n",
        "    all_token=[]\n",
        "    for token, token_id in all_tokens_and_ids:\n",
        "        all_token.append(token)\n",
        "    all_tokens=np.array(all_token)\n",
        "    return all_tokens"
      ],
      "metadata": {
        "id": "wGXi20uxgO9N"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################\n",
        "# TODO(6) -  Plot the alignments of the output tokens of the model and the input audio signal\n",
        "# For this, use the ctc_alignments function and the array of all tokens previously created\n",
        "############################\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "def plotting(test_data,all_tokens):\n",
        "    # Returns nothing, displays plot (save as image CTCalignments.png)\n",
        "    # Uses alignment computed two cells back\n",
        "    # Refer to the provided image in the assignment pdf for reference\n",
        "    # You can customize the plot further based on your requirements\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    heatmap = sns.heatmap(alignment.T, cbar_kws={'label': 'Alignment Score'})\n",
        "    heatmap.set_yticklabels(all_tokens[test_data[0]['tokens']], rotation=0)\n",
        "    plt.title(\"Alignment between output tokens and input audio signal\")\n",
        "    plt.ylabel(\"Output Tokens\")\n",
        "    plt.xlabel(\"Input Audio Timestep\")\n",
        "    plt.savefig(\"CTCalignments.png\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "eLwAC5qeYm2M"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_gt(tokenizer,ground_truth_tokens):\n",
        "    print(ground_truth_tokens[0])\n",
        "    print(tokenizer.decode([int(x) for x in ground_truth_tokens[0]]))"
      ],
      "metadata": {
        "id": "GM0TUMWkDIeD"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens=array_of_all_tokens(tokenizer)\n",
        "plotting(test_data,all_tokens)\n",
        "print_gt(tokenizer,ground_truth_tokens)"
      ],
      "metadata": {
        "id": "EE3Fzy_P0934",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 977
        },
        "outputId": "085fe2ad-6db4-4777-9cff-09d082dceb6c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([120,   7,  82,   4,   9,   1,  35,  47,  82,  57,  29,  26,  22,  90,\n",
            "         62,  16, 110,  11,  12, 145,   2,   1,  12,  50, 127,  31,   8,  69,\n",
            "          8,  24,  26, 112,  29,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0])\n",
            "ALL THE TIME HE WAS TALKING TO ME HIS ANGRY LITTLE EYES WERE FOLLOWING LAKE ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇ \n"
          ]
        }
      ]
    }
  ]
}